{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a238771-1b41-4018-817c-af3293332f54",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8a8437-7db2-40fc-927a-396fd2d2eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/26 18:56:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# set env\n",
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/home/cloud_user/apps/spark/current\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "\n",
    "# Import PySpark\n",
    "from pyspark.sql import SparkSession, Window\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"sparksql\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa374b0-aaf5-442e-a549-fcfb94938ba3",
   "metadata": {},
   "source": [
    "## Load data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec06123-e583-4810-a2d2-04e5324e6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "data_file_path = \"./data/products.csv\"\n",
    "df = spark.read.csv(data_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddf4000-e49a-46e0-ae02-bb15177f2851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n",
      "+---+--------------------+---------------+--------+------+\n",
      "| id|                name|       category|quantity| price|\n",
      "+---+--------------------+---------------+--------+------+\n",
      "|  1|           iPhone 12|    Electronics|      10|899.99|\n",
      "|  2|     Nike Air max 90|       Clothing|      25|119.99|\n",
      "|  3|KitchenAid Stand ...|Home Appliances|       5|299.99|\n",
      "|  4|    The Great Gatsby|          Books|      50| 12.99|\n",
      "|  5|L'Oreal Paris Mas...|         Beauty|     100|  9.99|\n",
      "|  6|            Yoga Mat|         Sports|      30| 29.99|\n",
      "|  7| Samsung 4k Smart TV|    Electronics|       8|799.99|\n",
      "|  8|        Levi's Jeans|       Clothing|      15| 49.99|\n",
      "|  9|Dyson Vacuum Cleaner|Home Appliances|       3|399.99|\n",
      "| 10|  Google Pixel 8 Pro|    Electronics|       4|699.99|\n",
      "+---+--------------------+---------------+--------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the Schema\n",
    "df.printSchema()\n",
    "# Show a sample\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5376903f-a7be-45a6-8181-08c7d5210c7c",
   "metadata": {},
   "source": [
    "## Register dataframe as a Temporary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07658de8-c8a8-428a-be25-f8f435e1a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bfd72-4763-44ca-ab33-c9ef08e9f3d1",
   "metadata": {},
   "source": [
    "## Perform SQL-Like Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c109f937-6ee0-4a50-8531-04aefa14f351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price greater than 20: 10\n",
      "+---+--------------------+---------------+--------+------+\n",
      "| id|                name|       category|quantity| price|\n",
      "+---+--------------------+---------------+--------+------+\n",
      "|  1|           iPhone 12|    Electronics|      10|899.99|\n",
      "|  2|     Nike Air max 90|       Clothing|      25|119.99|\n",
      "|  3|KitchenAid Stand ...|Home Appliances|       5|299.99|\n",
      "|  6|            Yoga Mat|         Sports|      30| 29.99|\n",
      "|  7| Samsung 4k Smart TV|    Electronics|       8|799.99|\n",
      "|  8|        Levi's Jeans|       Clothing|      15| 49.99|\n",
      "|  9|Dyson Vacuum Cleaner|Home Appliances|       3|399.99|\n",
      "| 10|  Google Pixel 8 Pro|    Electronics|       4|699.99|\n",
      "| 11|    Darth Vader Lego|           Toys|      10| 49.99|\n",
      "| 12|       Colosium Lego|           Toys|       2|500.98|\n",
      "+---+--------------------+---------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all rows where price is greater than 20\n",
    "result = spark.sql(\"SELECT * FROM products WHERE price > 20\")\n",
    "print(f\"Price greater than 20: {result.count()}\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf28327a-4ab9-4332-ab5b-210639e02d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+\n",
      "|       category|        avg_price|\n",
      "+---------------+-----------------+\n",
      "|         Sports|            29.99|\n",
      "|    Electronics|799.9900000000001|\n",
      "|       Clothing|            84.99|\n",
      "|          Books|            12.99|\n",
      "|Home Appliances|           349.99|\n",
      "|         Beauty|             9.99|\n",
      "|           Toys|          275.485|\n",
      "+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute revenue\n",
    "avg_price = spark.sql(\"SELECT category, AVG(price) as avg_price FROM products GROUP BY category\")\n",
    "avg_price.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281e030-9900-49b7-9dae-e5ab3e632a8a",
   "metadata": {},
   "source": [
    "## Checking if tables exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a096c76f-c27d-43b5-95ab-89b9d8ca74b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does products table exist? True\n"
     ]
    }
   ],
   "source": [
    "view_exists = spark.catalog.tableExists(\"products\")\n",
    "print(f\"Does products table exist? {view_exists}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699b947-c4bc-4c98-a694-8a922c39a969",
   "metadata": {},
   "source": [
    "## Dropping a Temporary View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160e4ea7-5d05-4fdd-840d-81466740fc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.dropTempView(\"products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d922317-c9ba-4920-aadb-4ae4f5a33736",
   "metadata": {},
   "source": [
    "## Subqueries\n",
    "Subqueries are nested SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85bd2302-4733-416b-95a9-7f0da179e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1|John|\n",
      "+---+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Create DataFrames\n",
    "employee_data = [\n",
    "    (1, \"John\"), (2, \"Alice\"), (3, \"Bob\"), (4, \"Emily\"), \n",
    "    (5, \"David\"), (6, \"Sarah\"), (7, \"Michael\"), (8, \"Lisa\"), \n",
    "    (9, \"William\")]\n",
    "employees = spark.createDataFrame(employee_data, [\"id\", \"name\"])\n",
    "employees.printSchema()\n",
    "employees.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bb6aca0-744d-4dde-b4b7-189367d60446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- department: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+----------+---+------+\n",
      "|department| id|salary|\n",
      "+----------+---+------+\n",
      "|        HR|  1| 60000|\n",
      "|        HR|  2| 55200|\n",
      "|        HR|  3| 58000|\n",
      "|        IT|  4| 70000|\n",
      "|        IT|  5| 72000|\n",
      "|        IT|  6| 68000|\n",
      "|     Sales|  7| 75000|\n",
      "|     Sales|  8| 78000|\n",
      "|     Sales|  9| 77000|\n",
      "+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salary_data = [\n",
    "    (\"HR\", 1, 60000), (\"HR\",2,55200), (\"HR\", 3, 58000),\n",
    "    (\"IT\", 4, 70000), (\"IT\", 5, 72000), (\"IT\", 6, 68000),\n",
    "    (\"Sales\", 7,75000), (\"Sales\", 8, 78000), (\"Sales\", 9, 77000)]\n",
    "salaries = spark.createDataFrame(salary_data, [\"department\",\"id\",\"salary\"])\n",
    "salaries.printSchema()\n",
    "salaries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "896275ec-b87e-46cb-ad37-b836e07f3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register temporary views\n",
    "employees.createOrReplaceTempView(\"employees\")\n",
    "salaries.createOrReplaceTempView(\"salaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d34a4e7-1381-4102-95d8-7b7142c6fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Emily|\n",
      "|  David|\n",
      "|Michael|\n",
      "|   Lisa|\n",
      "|William|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Subquery\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT e.name\n",
    "    FROM employees as e\n",
    "    WHERE e.id IN (\n",
    "        SELECT id\n",
    "        FROM salaries\n",
    "        WHERE salary > (SELECT AVG(salary) from salaries)\n",
    "    )\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6f200-5362-466b-8ca6-f6e18486de3e",
   "metadata": {},
   "source": [
    "## Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b514060-7454-4ad5-b48a-b682af4455bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+-------+\n",
      "|department| id|salary|   name|\n",
      "+----------+---+------+-------+\n",
      "|        HR|  1| 60000|   John|\n",
      "|        HR|  3| 58000|    Bob|\n",
      "|        HR|  2| 55200|  Alice|\n",
      "|        IT|  4| 70000|  Emily|\n",
      "|     Sales|  7| 75000|Michael|\n",
      "|        IT|  6| 68000|  Sarah|\n",
      "|     Sales|  9| 77000|William|\n",
      "|        IT|  5| 72000|  David|\n",
      "|     Sales|  8| 78000|   Lisa|\n",
      "+----------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a df of the two views joined\n",
    "employee_salary = spark.sql(\"\"\"\n",
    "    select salaries.*, employees.name\n",
    "    from salaries\n",
    "    left join employees on salaries.id = employees.id\n",
    "\"\"\")\n",
    "employee_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "315cf297-45e6-4174-8c17-3e88c2e05cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc, rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b25ebdc-c523-46f9-bbbc-3f1e086bc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a window spec\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(F.desc(\"salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25bab0c4-ac78-4540-8dae-b54fefcc9b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+-------+----+\n",
      "|department| id|salary|   name|rank|\n",
      "+----------+---+------+-------+----+\n",
      "|        HR|  1| 60000|   John|   1|\n",
      "|        HR|  3| 58000|    Bob|   2|\n",
      "|        HR|  2| 55200|  Alice|   3|\n",
      "|        IT|  5| 72000|  David|   1|\n",
      "|        IT|  4| 70000|  Emily|   2|\n",
      "|        IT|  6| 68000|  Sarah|   3|\n",
      "|     Sales|  8| 78000|   Lisa|   1|\n",
      "|     Sales|  9| 77000|William|   2|\n",
      "|     Sales|  7| 75000|Michael|   3|\n",
      "+----------+---+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the column \"rank\" within each department\n",
    "employee_salary.withColumn(\"rank\", F.rank().over(window_spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f54c3227-e391-49a2-a04a-ab01af977574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed5d74-42e4-4c5b-9e2c-3a52cf155cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
